# Lecture 1

# What is Computer Vision?

- Study of Vision Data
- 카메라가 널리 보급되면서 시각 데이터가 점점 늘어나는 중
- 이에 따라 이러한 데이터를 사용하기 위한 노력이 필요
- Computer Vision은 물리학, 생물학, 심리학, 수학, 엔지니어링, 컴퓨터사이언스의 개념을 모두 활용
    - 우리 눈에 보이는 사물들을 기하학적으로 재구성

# Computer Vision의 역사

- 인간/동물의 비전 뿐 아니라 컴퓨터 비전에도 영감을 준 생물학자들의 연구가 1950~60년도에 진행
    - “포유류의 시각적 처리 매커니즘은 무엇일까?” 에서 출발
    - 고양이 두뇌 뒷면에 전극을 꽂아 어떤 자극을 주어야 뉴런들이 반응하는지를 관찰
    - 시각처리는 처음에는 단순한 구조로 시작되어 그 정보가 통로를 거치면서 점점 더 복잡해짐
    
    <img width="505" alt="Untitled" src="https://user-images.githubusercontent.com/99728502/226164727-8c78e1d2-f8cf-4bec-87a5-67e46681b6c7.png">
    
- 컴퓨터 비전은 60년대 초반에 태동
- 1966년 MIT 프로젝트
    - 시각 시스템의 전반을 구현하기 위해 프로젝트 참가자들을 이용
    - 대부분의 시각체계를 구현하려는 시도
    - 여기부터 시작해 50년이 지난 지금 여전히 수천명의 연구자들이 비전을 연구하는 중

- David Marr (70년대 후반)
    
    ![Untitled](Lecture%201%2091fb505eb45548e998dda0adefcb505a/Untitled%201.png)
    
    - 비전의 정의, 발전 방향, 알고리즘 등을 저술
    - ‘우리가 눈으로 받아들인 이미지’를 ‘최종적인 Full 3D 표현’으로 만들기 위해 거쳐야 하는 과정을 설명
        - Primal Sketch : 대상의 경계, 막대, 끝점, 가상의 선, 커브 등이 표현되는 과정
        - 2.5-D Sketch : 시각장면을 구성하는 표면, 깊이, 레이어, 불연속 점과 같은 것들을 종합
        - 3-D Model Representation : 이전 단계의 모든 정보들을 모아 최종적인 3D로 모델링
    
- 1970년대 : 블록 같은 단순한 것을 넘어 실제 세계를 인식하고 표현하려는 시도
    
    ![Untitled](Lecture%201%2091fb505eb45548e998dda0adefcb505a/Untitled%202.png)
    
    - Generalized Cylinder : 원통 모양의 조합
    - Pictorial Structure : 주요 부위와 관절로 표현
    - 둘 다 모든 객체는 단순한 기하학적 형태로 표현할 수 있다는 개념에서 출발
    
- 80년대엔 어떻게 하면 단순한 구조로 실제 세계를 재구성/인식할 수 있을지 고민
    - 면도기를 인식하기 위해 면도기를 선과 경계, 직선의 조합으로 구성
- 60~80년대는 컴퓨터비전으로 어떤 일을 할 수 있을지를 고민한 시대
    - 하지만 그 시대에는 단순한 수준에 불과(컴퓨터 성능 등의 문제로 고차원적인 연구 불가)

- 객체인식이 너무 어렵다면 객체분할(Segmentation)부터 시작하는 것이 좋지 않을까? (1990)
    
    ![Untitled](Lecture%201%2091fb505eb45548e998dda0adefcb505a/Untitled%203.png)
    
    - 객체분할 : 이미지의 각 픽셀을 의미있는 방향으로 군집화하는 방법
    - 군집화된 이미지로 정확하게 사람을 인식할 수는 없겠지만, 적어도 배경인 픽셀과 사람인 픽셀을 구별할 수는 있음
    - Graph Therory를 적용

- Face Detection(2001)
    - 90~00년대에는 SVM, Boosting, Graphical Model, 초기 Neural Network와 같은 통계적 머신러닝 기법을 주로 사용
    - 기존의 비전 연구들과는 다르게, 2006년 실시간 얼굴 인식을 지원하는 카메라가 개발되며 기초과학연구를 실제 응용제품으로 가장 빠르게 전달한 사례 중 하나로 자리매김

- 어떻게 객체를 잘 인식할 것인가?
    
    ![Untitled](Lecture%201%2091fb505eb45548e998dda0adefcb505a/Untitled%204.png)
    
    - 90~10년도엔 ‘특징기반 객체인식 알고리즘’이 중시
        - 카메라 앵글, 빛, 화각 등의 문제로 같은 객체도 변할 수 있음
        - 하지만 객체의 특징 중 일부는 다양한 변화에 조금 더 강인하고 불변하다는 점을 발견
        - 객체인식은 객체에서 중요한 특징을 찾아내고, 그 특징을 다른 객체에 매칭시키는 과제가 되어 보다 더 쉬워짐
    - 위 사례에선 ‘STOP’ 글씨를 특징으로 삼아 확인
    - 이미지에 존재하는 ‘특징’을 사용하게 되면서 비전 연구는 한 단계 도약하게 되었고, 장면 전체도 인식 가능해짐
        - Spatial Pyramid Maching : ‘특징’들을 잘 뽑아내기만 한다면 그 특징이 일종의 단서를 제공해 이 장면이 어느 장소인지 등을 추정할 수 있음(SVM 사용)
    - 00년대에 들어서 사진의 품질이 이전보다 훨씬 좋아짐. 객체인식이 이 시기들어 다시 대두되기 시작
    - 객체인식 기술의 성능을 측정하기 위해 여러 벤치마크 데이터셋이 만들어짐
    
- 기존에 사용하던 Graphical Model, SVM, AdaBoost 같은 머신러닝 알고리즘들이 훈련 과정에서 Overfitting하기 쉬웠음 → 시각 데이터가 너무 복잡하기 때문
    - 이로 인해 모델을 Fitting 하려면 더 많은 파라미터가 필요
    - 컴퓨터 비전의 연구에는 2가지 동기가 존재
        - 세상의 모든 것을 인식하자
        - 머신러닝의 Overfitting 문제를 극복하자
        - 이 동기를 바탕으로 ImageNet 프로젝트가 탄생
    - ImageNet 덕분에 객체인식은 새로운 국면으로 진입
        - 2012년부터 사람보다 더 좋은 인식율을 기록
        - 아직 객체인식의 모든 문제를 풀지 못했지만, 실생활에 적용하기에는 괜찮은 성능을 기록
        - 2012년 CNN이 모든 알고리즘을 능가하고 우승했는데, 기존의 오류율보다 훨씬 적은 오류율을 기록하는 등 객체인식에서의 새로운 분기점이 됨
    

## 간단한 개념 정리 및 수업 내용 소개

- Image Classification : 이미지를 보고 주어진 답안 후보중에 가장 가까운 답을 선택
- Object Detetion : 이 이미지가 무슨 객체이며, 이 객체의 영역은 어디인지까지 네모박스를 그려야 함
- Image Captioning : 이미지가 주어지면 이미지를 묘사하는 설명을 출력

- (2017년 기준) 비전 분야의 혁신을 이루어낸 모델은 CNN
    - 2012년 AlexNet이 우승을 차지한 이후 우승 모델은 항상 CNN의 몫.
    - 2014년 GoogLeNet, VGG
    - 2015년 ResNet

- CNN은 2012년부터 본격적으로 사용되었지만, 기초적인 연구는 1998년에 시작
    - 당시엔 숫자인식을 위해 CNN을 구축
    - 자필 수표 판독과 우편주소 판독을 위해 사용
    - 2012년에 본격적으로 사용된 이유는 컴퓨터 성능의 발전, GPU의 진보, 충분한 데이터 등이 이유

- 컴퓨터 비전 연구의 목적은 사람처럼 볼 수 있는 모델을 만드는 것
    - 인간의 시각체계는 컴퓨터보다 훨씬 강력
    - 이를 위해 아직도 수많은 도전과제와 문제들이 남아있음
    - 예를 들어, Semantic Segmentation(모든 픽셀 하나하나를 이해), 3D understanding(실세계를 재구성) 등의 문제가 존재
    - 이미지 뿐 아니라, 사진 속의 상황을 이해하는 데에도 한계가 있음

정복된 분야 발표 때 언급
