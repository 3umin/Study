# [CS224n] Lecture 11

# Question Answering

![1.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/1.png)

- ì‚¬ëŒì˜ ì§ˆë¬¸ì— ë§ê²Œ ìì—°ì–´ë¡œ ìë™ì ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” ì‹œìŠ¤í…œ
- ì ì ˆí•œ ë¬¸ì„œë¥¼ ì¶œë ¥í•˜ëŠ” ì •ë³´ ê²€ìƒ‰(Information Retriever)ê³¼ ë‹¤ë¥´ê²Œ, ê°„ë‹¨í•œ êµ¬ë¡œ ì´ë£¨ì–´ì§„ ì •ë‹µì„ ì¶œë ¥
- ë¶„ë¥˜ê°€ í•µì‹¬
    - ì–´ë– í•œ ì†ŒìŠ¤ë¡œë¶€í„° ì •ë³´ë¥¼ í™œìš©í•˜ëŠ”ê°€?
        - ì±…ì˜ êµ¬ì ˆ, ì›¹ ë¬¸ì„œ, ì‚¬ì§„, knowledge bases, tables ë“±ë“±ë“±
    - ì§ˆë¬¸ì˜ ìœ í˜•
        - ê°„ë‹¨í•œ vs ë³µì¡í•œ, closed-domain(íŠ¹ì •ì˜ì—­ í•œì •) vs open-domain ë“±ë“±
    - ì‘ë‹µì˜ ìœ í˜•
        - ì§§ì€ í…ìŠ¤íŠ¸ ë¬¸êµ¬, ë‹¨ë½, ë¦¬ìŠ¤íŠ¸, O X ë“±ë“±

- ê°€ì¥ í”í•œ ì˜ˆì‹œ

![2.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/2.png)

- QAì˜ êµ¬ì¡°
    - ëŒ€ë¶€ë¶„ì˜ QAëŠ” end-to-end trainingê³¼ BERTê°™ì€ pretraining ê¸°ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë£¨ì–´ì§

![3.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/3.png)

- ìš”ì¦˜ì—ëŠ” ë¬¸ìì ì¸ QAë¥¼ ë„˜ì–´ì„œ, ì´ë¯¸ì§€ë‚˜ ì˜ìƒ ë“±ì—ì„œì˜ ì§ˆë¬¸ê¹Œì§€ ë‹µí•˜ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „
    
    ![4.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/4.png)
    

# Reading comprehension

![5.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/5.png)

- ì •í•´ì§„ êµ¬ì ˆì„ ì´í•´í•œ ë’¤ ê·¸ ë‚´ìš©ì— ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ê²ƒ
- â€˜ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥â€™ì´ ê°€ì¥ ê°•ë ¥í•œ ì´í•´ì˜ í‘œì‹œì´ë¯€ë¡œ, reading comprehensionì€ ë§¤ìš° ì¤‘ìš”
- ê¸´ ë¬¸ì¥ì—ì„œ ì •ë³´ì˜ ì¶”ì¶œ, ê·¸ë¦¬ê³  ì˜ë¯¸ì ì¸ ì—­í• ì˜ ë¼ë²¨ë§ì´ ê°€ëŠ¥

![6.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/6.png)

# Standford Question Answering dataset(SQuAD)

- ì•½ 10ë§Œê°œì˜ ì£¼ì„ì´ ë‹¬ë¦° (êµ¬ì ˆ, ì§ˆë¬¸, ì •ë‹µ) 3ê°œ ì„¸íŠ¸
    - êµ¬ì ˆì€ ì˜ì–´ ìœ„í‚¤í˜ë””ì•„ì—ì„œë„ ìˆ˜ì§‘
    - ì§ˆë¬¸ì€ ì¼ë°˜ì¸ë“¤ì—ê²Œì„œ ìˆ˜ì§‘
    - ê° ì •ë‹µì€ êµ¬ì ˆ ì†ì— ìˆëŠ” ì§§ì€ ë¬¸êµ¬ë¡œ ì‘ì„±
    - ê° ì •ë‹µì€ 3ê°œì˜ Gold answerë¡œ ìˆ˜ì§‘(ë‹¤ì–‘í•œ ì •ë‹µì´ ìˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸)
- í‰ê°€ë°©ë²• : Exact match(ë§ìœ¼ë©´ 1, í‹€ë¦¬ë©´ 0)ê³¼ F1-score(ë¶€ë¶„ì ìˆ˜)ë¥¼ í•¨ê»˜ í™œìš©

# Neural models for reading comprehension

- Input : $C = (c_1,c_2, ...\ ,c_N), Q = (q_1, q_2, ... \ , q_M)$
- Output : $1 \le start \le end \le N$

- seq2seq model with attention

![7.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/7.png)

passageì— ìˆëŠ” ì–´ë–¤ ë‹¨ì–´ê°€ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì´ ìˆëŠ”ì§€ë¥¼ ì•Œì•„ì•¼í•¨

## BiDAF : Bidirectional Attetion Flow model

![8.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/8.png)

### BiDAF: Encoding

![9.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/9.png)

- ê°ê°ì˜ ë¬¸ë§¥ê³¼ ì¿¼ë¦¬ ì†ì˜ ë‹¨ì–´ì— ëŒ€í•´ word embedding(GloVe)ê³¼ character embeddingì„ ë°˜ë³µí•œ ìë£Œë¥¼ ì‚¬ìš©
    
    $e(c_i) = f([GloVe(c_i); charEmb(c_i]) \ \ \ \ \ e(qi) = f([GloVe(q_i);charEmb(q_i)])$
    
- ê·¸ëŸ° ë‹¤ìŒ, ë¬¸ë§¥ê³¼ ì¿¼ë¦¬ë¥¼ ìœ„í•œ contextual embeddingì„ ë§Œë“¤ê¸° ìœ„í•´ ë‘ê°œì˜ ì–‘ë°©í–¥ LSTMì„ ê°ê° ì‚¬ìš©

### BiDAF: Attention

![10.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/10.png)

- ë¨¼ì €, ëª¨ë“  ì§ $(c_i, q_j)$ì— ëŒ€í•´ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°:
    
    $S_{i,j} = w^T_{sim}[c_i;q_j;c_i \odot q_j] \in R \ \ \ \ \ \ \ w_{sim} \in R^{6H}$
    
- context-to-query attention : ê°ê°ì˜ context ë‹¨ì–´ì— ëŒ€í•´, ê°€ì¥ ê´€ë ¨ëœ ë‹¨ì–´ë¥¼ query ë‹¨ì–´ì¤‘ì—ì„œ ë½‘ìŒ
    
    $\alpha_{i,j} = softmax_j(S_{i,j}) \in R \ \ \ \ \ \ a_i = \sum_{j=1}^M \alpha_{i,j}q_j \in R^{2H}$
    

![11.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/11.png)

- query-to-context attention : ê°ê°ì˜ query ë‹¨ì–´ì— ëŒ€í•´ ê°€ì¥ ê´€ë ¨ìˆëŠ” context ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ë½‘ìŒ
    
    $\beta_i = softmax_i(max_{j=1}^M(S_{i,j})) \in R^N \ \ \ \ \ \ \ b_i = \sum_{i=1}^N \beta_ic_i \in R^{2H}$
    

![12.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/12.png)

- ìµœì¢… ê²°ê³¼ëŠ” $g_i =[c_j;a_i;c_i \odot a_i;c_i \odot b_i] \in R^{8H}$
- Modeling Layer : context word ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ ëª¨ë¸ë§
    
    $m_i = BiLSTM(g_i) \in R^{2H}$
    
- Output layer : startì™€ end positionì„ ì˜ˆì¸¡í•˜ëŠ” ë‘ê°œì˜ ë¶„ë¥˜ê¸°
    
    $p_{start} = softmax(w^T_{start}[g_i;m_i]) \ \ \ \ \ \ \ \ \ p_{end} = softmax(w^T_{end}[g_i;m_i']) \\m'_i = BiLSTM(m_i)$
    
- ìµœì¢… ì†ì‹¤í•¨ìˆ˜ëŠ” $L = -log(p_{start}(s^*)) - log(p_{end}(e^*))$ë¡œ í‘œí˜„

## Bert for reading comprehension

![13.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/13.png)

- BERTëŠ” ë§ì€ ì–‘ì˜ í…ìŠ¤íŠ¸ì— ëŒ€í•´ pre-trained ëœ deepí•œ ì–‘ë°©í–¥ Transformer encoder

![14.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/14.png)

- Question = Segment A
- Passage(êµ¬ì ˆ) = Segment B
- Answer = Segment Bì—ì„œ ë‘ê°œì˜ endpointë¥¼ ì˜ˆì¸¡

- BERTì™€ BiDAFì˜ ë¹„êµ
    - BERT ëª¨ë¸ì€ 110 million or 330 million ì •ë„ì˜ ì•„ì£¼ ë§ì€ ëª¨ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ” ë°˜ë©´, BiDAFëŠ” ~2.5million parameter
    - BiDAFëŠ” ì—¬ëŸ¬ê°œì˜ ì–‘ë°©í–¥ LSTMì„ í†µí•´ ë§Œë“¤ì–´ì§€ê³ , BERTëŠ” Transformerì„ í†µí•´ ë§Œë“¤ì–´ì§
    - BERTëŠ” pre-train ë˜ì—ˆì§€ë§Œ, BiDAFëŠ” GloVeë¥¼ í†µí•´ì„œë§Œ ë§Œë“¤ì–´ì§
    - BiDAFì™€ ë‹¤ë¥¸ ëª¨ë¸ì€ ì§ˆë¬¸ê³¼ êµ¬ì ˆì˜ ìƒí˜¸ì‘ìš©ì„ ëª¨ë¸ë§ í•˜ëŠ”ë°ì— ì¤‘ì 
    - BERTëŠ” ì§ˆë¬¸ê³¼ êµ¬ì ˆ ì‚¬ì´ì—ì„œ self-attentionì„ ì‚¬ìš© â†’ ë‘˜ì´ ê·¼ë³¸ì ìœ¼ë¡  ìœ ì‚¬

# Can we design better-pretraining objectives?

![15.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/15.png)

Two ides

- 15%ì˜ ë¬´ì‘ìœ„ ë‹¨ì–´ ëŒ€ì‹  ê·¼ì ‘í•œ ë‹¨ì–´ë“¤ì„ ë§ˆìŠ¤í‚¹
- ë§ˆìŠ¤í‚¹ëœ ë‹¨ì–´ì˜ ì˜ˆì¸¡ì„ í•  ë•Œ 2ê°œì˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©
    
    $y_i = f(x_{s - 1}, x_{e+1}, p_{i-s+1})$
    

SQuAD ë°ì´í„°ì…‹ì—ì„œ ì¸ê°„ì˜ ì ìˆ˜ë³´ë‹¤ ì´ë¯¸ ë” ë†’ì€ ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆëŠ”ë°, ê·¸ë ‡ë‹¤ë©´ reading comprehensionì€ ì™„ë²½í•œê°€?

- No, ìƒë°˜ë˜ëŠ” ë¬¸êµ¬ì— ëŒ€í•œ reading comprehensionì˜ ì„±ëŠ¥ì€ ë‚®ìŒ
- ê·¸ë¦¬ê³  í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨í•œ ëª¨ë¸ì€ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì¼ë°˜í™”í•˜ì§€ ëª»í•¨

# Open-domain Question Answering

![16.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/16.png)

- ì£¼ì–´ì§„ ì§ˆë¬¸ì— ê´€ë ¨ëœ êµ¬ì ˆì´ ë”°ë¡œ ì—†ê³ , ìœ„í‚¤í˜ë””ì•„ ê°™ì´ ë§ì€ ë¬¸ì„œë¥¼ ëª¨ì•„ë‘” ê³³ì— ìˆëŠ” êµ¬ì ˆì„ í™œìš©
- ë‹µì´ ì–´ë””ìˆëŠ”ì§€ëŠ” ëª¨ë¥´ê³ , í•˜ë‚˜ì˜ open-domain ì§ˆë¬¸ì— ëŒ€í•´ ë‹µì„ ì£¼ëŠ” ê²ƒì´ ëª©í‘œ
    
    â†’ ë”ìš± ë” ì–´ë µì§€ë§Œ ë³´ë‹¤ ë” í˜„ì‹¤ì ì¸ ë¬¸ì œ!
    

## Retriver-reader framework(ê²€ìƒ‰-ì½ê¸° í”„ë ˆì„ì›Œí¬)

- Retriver : $f(ğ’Ÿ, Q)$  â†’ $P_1, ... \ , P_K$,              ğ’Ÿ: large collection of documents
- Reader : $g(Q, \left\{P_1, ...\ , P_K \right\})$ â†’ A              A : an answer string

![17.PNG](%5BCS224n%5D%20Lecture%2011%204fd32615a4074b79bda07445fb68b21a/17.png)

- Retriever(ê²€ìƒ‰ê¸°)ë„ í›ˆë ¨í•  ìˆ˜ ìˆìŒ!
    - ê°ê°ì˜ êµ¬ì ˆì€ BERTë¥¼ ì‚¬ìš©í•´ì„œ vectorë¡œ ì¸ì½”ë”© ë  ìˆ˜ ìˆê³ , retriver scoreì€ ì§ˆë¬¸ì— ëŒ€í•œ ì¸ì½”ë”©ê°’ê³¼(ë²¡í„°) êµ¬ì ˆì— ëŒ€í•œ ì¸ì½”ë”© ê°’ì˜ ë‚´ì ì„ í†µí•´ ê³„ì‚°í•  ìˆ˜ ìˆìŒ
    - í•˜ì§€ë§Œ, ë„ˆë¬´ë‚˜ë„ ë§ì€ êµ¬ì ˆì´ ìˆê¸° ë•Œë¬¸ì— ëª¨ë“  ë²¡í„°ë¥¼ êµ¬í•˜ëŠ”ë°ì— ìˆì–´ ì–´ë ¤ì›€ì´ ìˆìŒ

- Reader ëª¨ë¸ì´ ì—†ì–´ë„ ë˜ëŠ” ê°€ëŠ¥ì„±ì´ ì¡´ì¬
    - ëª¨ë“  êµ¬ë¬¸ì„ ì¸ì½”ë”©í•˜ëŠ”ê²Œ ê°€ëŠ¥, dense vectorì„ ì´ìš©í•˜ì—¬ BERTë¥¼ ì“°ì§€ ì•Šê³ , nearest neighbor searchë¥¼ í•  ìˆ˜ ìˆìŒ