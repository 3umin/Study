{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256734f4",
   "metadata": {},
   "source": [
    "# 7.1 Sequential 모델을 넘어서: 케라스의 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e2124",
   "metadata": {},
   "source": [
    "Sequential 모델은 네트워크의 입력과 출력이 하나로 가정한 뒤 층을 차례대로 쌓아 구성.\n",
    "\n",
    "하지만 이런 가정이 맞지 않는 경우도 많음. 일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요하며, 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 존재.\n",
    "\n",
    "인풋 데이터로 여러 타입의 데이터를 입력받을 때(연도 브랜드 등 - 완전연결모듈, 텍스트 - RNN or Conv1D, 이미지 - Conv2D) 각각의 모델을 따로 훈련하고 각 예측의 가중평균을 통해 구할 수 있지만, 이는 최적의 방법이 아님\n",
    "\n",
    "가능한 모든 종류의 입력 데이터를 동시에 사용해서 정확한 하나의 모델을 학습하는 것이 더 나은 방법.\n",
    "\n",
    "위의 경우 완전연결모듈, RNN 모듈, 컨브넷 모듈로 나누어 3개의 입력가지를 통해 하나의 모델을 학습하는 경우가 베스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877661e9",
   "metadata": {},
   "source": [
    "또는 입력데이터로부터 여러 개의 타깃 속성을 예측해야 하는 경우도 존재\n",
    "\n",
    "짧은 글을 입력받았을 때 장르와 글이 써진 대략의 시대를 예측해야하는 경우가 하나의 예.\n",
    "\n",
    "이 경우도 마찬가지로 2개의 모델을 따로 훈련할 수 있지만 이 속성들은 통계적으로 독립적이지 않기 때문에 동시에 같이 예측하도록 해야 더 좋은 모델이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762a1ca",
   "metadata": {},
   "source": [
    "기존에는 여러 모델을 거쳐 하나의 텐서로 합쳐지는 모델이 전통적이였으나, 최근에는 하위층의 텐서 연산을 상위층에 넣는 잔차연결 기법도 활용. (1 2 3 4 층이 있을 때 1 -> 2 -> 3 -> 4 로 가는 방향은 동일하나, 2가 3과 4 모두 가는 느낌)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e293e",
   "metadata": {},
   "source": [
    "## 7.1.1 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e043158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf0f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 간단한 예시를 통해 Sequential과 함수형 API를 비교\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(64,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)       # 입력텐서와 출력텐서만 가지고 모델 객체 생성\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704edbc9",
   "metadata": {},
   "source": [
    "## 7.1.2 다중 입력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2108bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 입력을 가진 질문-응답 모델의 함수형 API\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')      # 길이가 정해지지 않은 정수 시퀀스 입력\n",
    "\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)    # 인코딩된 질문과 텍스트를 연결\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d43248",
   "metadata": {},
   "source": [
    "## 7.1.3 다중 출력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f6e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 출력을 가진 함수형 API\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "post_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(post_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(post_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# 또는 loss={'age':'mse', 'income':'categorical_crossentropy', 'gender':'binary_crossentropy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e3487",
   "metadata": {},
   "source": [
    "## 7.1.4 층으로 구성된 비순환 유향 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9cfd9",
   "metadata": {},
   "source": [
    "- 비순환 유향 그래프 : 텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b39c02",
   "metadata": {},
   "source": [
    "### 인셉션 모듈 : 네트워크 안의 네트워크 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape 없어서 실행하면 에러남\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, acitvation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b3060",
   "metadata": {},
   "source": [
    "### 잔차 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940cbf6d",
   "metadata": {},
   "source": [
    "Gradient Vanishing과 Representational bottleneck을 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])      # 원본 x를 출력 특성에 더함\n",
    "# 위에처럼 원본을 넣어도 되고, 합성곱층을 한번 거친 값을 x 대신 넣어줘도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434a83a",
   "metadata": {},
   "source": [
    "## 7.1.5 층 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09933bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49416aae",
   "metadata": {},
   "source": [
    "## 7.1.6 층과 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c0ee9",
   "metadata": {},
   "source": [
    "함수형 API에서는 모델을 층처럼 이용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93eaa772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfeb1d",
   "metadata": {},
   "source": [
    "# 7.2 케라스 콜백과 텐서보드를 사용한 딥러닝 모델 검사와 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc76fc7",
   "metadata": {},
   "source": [
    "## 7.2.1 콜백을 사용하여 모델의 훈련 과정 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a334d21",
   "metadata": {},
   "source": [
    "- 모델 체크포인트 저장 : 훈련하는 동안 어떤 지점에서 모델의 현재 가중치를 저장\n",
    "- 조기 종료 : 검증 손실이 더이상 향상되지 않을 때 훈련을 중지\n",
    "- 훈련하는 동안 하이퍼파라미터 값을 동적으로 조정\n",
    "- 훈련과 검증 지표를 로그에 기록하거나 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db97432",
   "metadata": {},
   "source": [
    "### ModelCheckpoint와 EarlyStopping 콜백"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_acc', patience=1),        # 1 에포크보다 더 길게 정확도가 향상되지 않으면 훈련 중지\n",
    "    keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss', save_best_only=True)    # 에포크마다 가중치 저장\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45a03b",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abf941",
   "metadata": {},
   "source": [
    "검증 손실이 향상되지 않을 때 학습률을 작게 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)\n",
    "    # 콜백이 호출될 때 학습률을 factor(10배로 줄임)만큼 조정\n",
    "]\n",
    "\n",
    "model.fit(x, y, eopchs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54de5cd",
   "metadata": {},
   "source": [
    "### 나만의 콜백 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be7440ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layers_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "        \n",
    "        validation_sample = self.validation_Data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'wb')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d1ac9",
   "metadata": {},
   "source": [
    "## 7.2.2 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d090ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.Embedding(max_features, 128, input_length=max_len, name='embed'),\n",
    "    layers.Conv1D(32, 7, activation='relu'),\n",
    "    layers.MaxPooling1D(5),\n",
    "    layers.Conv1D(32, 7, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02fd0407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 29s 176ms/step - loss: 0.6192 - acc: 0.6430 - val_loss: 0.5599 - val_acc: 0.7920\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.4487 - acc: 0.8461 - val_loss: 0.4124 - val_acc: 0.8594\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 30s 193ms/step - loss: 0.3798 - acc: 0.8797 - val_loss: 0.3965 - val_acc: 0.8638\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.3178 - acc: 0.9044 - val_loss: 0.5054 - val_acc: 0.8596\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2996 - acc: 0.9197 - val_loss: 0.6636 - val_acc: 0.8514\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.2396 - acc: 0.9405 - val_loss: 0.6455 - val_acc: 0.8674\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2139 - acc: 0.9518 - val_loss: 0.6893 - val_acc: 0.8738\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.1753 - acc: 0.9660 - val_loss: 0.7357 - val_acc: 0.8686\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 30s 189ms/step - loss: 0.1493 - acc: 0.9800 - val_loss: 0.7751 - val_acc: 0.8664\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 29s 184ms/step - loss: 0.1257 - acc: 0.9834 - val_loss: 0.9766 - val_acc: 0.8628\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 31s 196ms/step - loss: 0.1374 - acc: 0.9857 - val_loss: 1.0712 - val_acc: 0.8548\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.0961 - acc: 0.9929 - val_loss: 0.9541 - val_acc: 0.8706\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 30s 191ms/step - loss: 0.1061 - acc: 0.9896 - val_loss: 1.1497 - val_acc: 0.8620\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 30s 192ms/step - loss: 0.1017 - acc: 0.9901 - val_loss: 1.2057 - val_acc: 0.8560\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 30s 194ms/step - loss: 0.1029 - acc: 0.9891 - val_loss: 1.0811 - val_acc: 0.8676\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 31s 196ms/step - loss: 0.0957 - acc: 0.9906 - val_loss: 1.1137 - val_acc: 0.8692\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 31s 198ms/step - loss: 0.0960 - acc: 0.9915 - val_loss: 1.1670 - val_acc: 0.8688\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 31s 197ms/step - loss: 0.1032 - acc: 0.9901 - val_loss: 1.1747 - val_acc: 0.8658\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 31s 195ms/step - loss: 0.0929 - acc: 0.9916 - val_loss: 1.2018 - val_acc: 0.8674\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 31s 196ms/step - loss: 0.0955 - acc: 0.9916 - val_loss: 1.8996 - val_acc: 0.8160\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.TensorBoard(log_dir = 'my_log_dir', histogram_freq = 1, embeddings_freq=1)]\n",
    "  # 1 에포크마다 활성화 출력의 히스토그램을, 임베딩 데이터를 기록\n",
    "    \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44a22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 실행중에 http://localhost:6006 에 접속하면 나옴\n",
    "!tensorboard --logdir=my_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76184da5",
   "metadata": {},
   "source": [
    "# 7.3 모델의 성능을 최대로 끌어올리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023aa0ac",
   "metadata": {},
   "source": [
    "## 7.3.1 고급 구조 패턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d63566",
   "metadata": {},
   "source": [
    "### 배치 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650edb9",
   "metadata": {},
   "source": [
    "- 정규화 : 머신러닝 모델에 주입되는 샘플들을 균일하게 만드는 방법(표준정규화)\n",
    "\n",
    "하지만 네트워크의 각각의 층에서 변환된 후에도 정규화된 데이터가 출력되진 않음 -> 배치정규화\n",
    "\n",
    "훈련하는동안 평균과 분산이 바뀌더라도 이에 맞게 데이터를 계속 정규화하기 때문에, 그라디언트의 전파에 큰 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 합성곱이나 완전연결층(Dense) 다음에 사용\n",
    "\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "conv_model.add(layers.Dense(32, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a19927",
   "metadata": {},
   "source": [
    "### 깊이별 분리 합성곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a0e6c",
   "metadata": {},
   "source": [
    "Conv2D를 대체하면서 더 가벼우며 성능이 좋은 층\n",
    "\n",
    "제한된 데이터로 작은 모델을 처음부터 훈련시킬 때 효과적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d89f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "\n",
    "height=64\n",
    "width=64\n",
    "channels=3\n",
    "num_classes=10\n",
    "\n",
    "model = Sequential([\n",
    "    layers.SeparableConv2D(32, 3, activation='relu', input_shape=(height, width, channels,)),\n",
    "    layers.SeparableConv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    \n",
    "    layers.SeparableConv2D(64, 3, activation='relu'),\n",
    "    layers.SeparableConv2D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    \n",
    "    layers.SeparableConv2D(64, 3, activation='relu'),\n",
    "    layers.SeparableConv2D(128, 3, activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba016ad",
   "metadata": {},
   "source": [
    "## 7.3.2 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b6f2f",
   "metadata": {},
   "source": [
    "1. 일련의 하이퍼파라미터를 선택\n",
    "2. 선택된 하이퍼파라미터로 모델 생성\n",
    "3. 훈련 데이터에 학습하고 검증 데이터에서 최종 성능 측정\n",
    "4. 다음으로 시도할 하이퍼파라미터를 선택\n",
    "5. 이 과정 반복\n",
    "6. 마지막으로 테스트셋에서 성능 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb18045",
   "metadata": {},
   "source": [
    "## 7.3.3 모델 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafbb9d",
   "metadata": {},
   "source": [
    "- 앙상블 : 다른 여러개 모델의 예측을 합쳐 더 좋은 예측을 만듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
