{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1946a5c7",
   "metadata": {},
   "source": [
    "# 8.1 LSTM으로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71703ea",
   "metadata": {},
   "source": [
    "## 8.1.2 시퀀스 데이터를 어떻게 생성할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5543d91",
   "metadata": {},
   "source": [
    "딥러닝에서 시퀀스를 생성하는 일반적인 방법은 이전 토큰들이 주어졌을 때 다음 토큰의 확률을 모델링하는 Language Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ca6e1",
   "metadata": {},
   "source": [
    "## 8.1.3 샘플링 전략의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af602db9",
   "metadata": {},
   "source": [
    "텍스트를 생성할 때 다음 글자를 선택하는 방법들.\n",
    "\n",
    "- Greedy Sampling : 단순히 항상 가장 높은 확률을 가진 글자를 선택 -> 논리적인 언어로 보이지 않음\n",
    "- Stochastic Sampling : 다음 글자를 확률적으로 선택(e가 0.3의 확률이면 10번 중 3번은 e 선택)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f5281",
   "metadata": {},
   "source": [
    "## 8.1.4 글자 수준의 LSTM 텍스트 생성 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a08ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "600901/600901 [==============================] - 1s 2us/step\n",
      "말뭉치 크기: 600893\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "\n",
    "print('말뭉치 크기:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1246692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시퀀스 개수: 200278\n",
      "고유한 글자: 58\n",
      "벡터화...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\AppData\\Local\\Temp\\ipykernel_15108\\3939754824.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\ytnal\\AppData\\Local\\Temp\\ipykernel_15108\\3939754824.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# 글자 시퀀스 벡터화\n",
    "\n",
    "maxlen = 60\n",
    "step = 3\n",
    "\n",
    "sentences=[]\n",
    "next_chars = []     # 타깃(다음 글자)를 담을 리스트\n",
    "\n",
    "for i in range(0, len(text)-maxlen, step):\n",
    "    sentences.append(text[i: i+maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('시퀀스 개수:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('고유한 글자:', len(chars))\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print('벡터화...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6ed9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 구성\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.LSTM(128, input_shape=(maxlen, len(chars))),\n",
    "    layers.Dense(len(chars), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5bc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 예측이 주어졌을 때 새로운 글자를 샘플링하는 함수\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1005c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1\n",
      "1565/1565 [==============================] - 115s 72ms/step - loss: 1.9499\n",
      "--- 시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
      "through fo\"\n",
      "------ 온도: 0.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for the senser of the soult the soult of the so the sense that the so the soult of the so the same and which the soult that the which the soul and the soult and the so the soul and the so the many in the strong and which the man to a sake of the most the soul and such a so the so the stringer and life the strong to the soult and all the soult to the strong of the same to the soult that the strenge t\n",
      "------ 온도: 0.5\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for the cause and the could to a being that the from the lattle and\n",
      "compless of the while of the exprinding so that the as in thesely hould that the senser sen and he who success of have not men the which the manser and so the ferthers and so the strough that the acted that and moough that the man to see doder, and there for the chould to the in the estant of a pricoust which would that in which is \n",
      "------ 온도: 1.0\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for thy led an possible, indifuence which, at all they as a quality: with the onligation\n",
      "wher parely not the dastual moking for indesting, doops and s frinesth? as\n",
      "all he which is not woikest in that there-upon.\n",
      "\n",
      "fuce,\n",
      "thjugs only may steeng to explocon--that with\n",
      "ene, tho valuand and daminacur wherale of miture that hele -hexirous threstoners life, as somity afulourse beniny of thus were with -the \n",
      "------ 온도: 1.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for that\n",
      "evinct\n",
      "of would how could af this arcolman med. hardny preceses litt and houde by voety as in, caz whice  hat hit, the\n",
      "woman nacletracry life egvinofresthers\n",
      "ferse of this deves of spiriss\n",
      "goegic soul,\n",
      "finstion, amh ajo-; haves un[nablderisathicouldgd4ousnes that he 5hougatory care ase\n",
      "own whatnou\n",
      "eving, an ock, any know he himpers uplow beingning of thos\n",
      "that in lake\n",
      "apprecomove abouges: b\n",
      "에포크 2\n",
      "1565/1565 [==============================] - 122s 78ms/step - loss: 1.6123\n",
      "--- 시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
      "through fo\"\n",
      "------ 온도: 0.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for the strength and the stand of the same and in the self-more of the desires and also of the actions of the same and some and all the soul and as a present and supperiate to the still all the soul and as a present to the supporaticism of the spiritually and the same and all the same and soul and all the strong the strength and as a the present the soul and as a more and come to the self-superities\n",
      "------ 온도: 0.5\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for a metaphysically be imperied for the desires it is one to all the act of some and develops of a not the courtic have eness and vising of the fail. the vicious the most sakes and the more the supporaticism for the condectances of a germany to wooling and wordates and conscience of the present in the truth to grate which is forgethess and does to be\n",
      "apprety of the desired of self-discience of at t\n",
      "------ 온도: 1.0\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through fous in exall chataps speaugely it is a chriscable rescide that a man certain egons\" to of us, nestless and on\n",
      "is at i\n",
      "kipphicaly\" mingud adomd, as if noble suspectitutly himself what is ampo \"caulled ecomen of oresplenweld eor in the\n",
      "sticks: \"ally increness\n",
      "of its\n",
      "so truty wrow, imponative raftiness\n",
      "of it is colder and mual\n",
      "its to pord antidenity, which an erruled\n",
      "plaored\n",
      "alld previence to comeat o\n",
      "------ 온도: 1.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through fol moring eacher\" yeans of\n",
      "ogen to , the\n",
      "simrling trde\" is tratipularnish sup, in order thy\n",
      "evolutable in.oceal actiquutem words. wiman ssaching philosopher one to ihouldrs make racamen\n",
      "for boed me.. the conscient of the foourity--diace is\n",
      "accorcums deluctiond; \"he no\n",
      "l\n",
      "skep\" agesesve, \"evency, happiness withortes patients becremisqmornctjes, of the poulst\n",
      "of the sgemings freen for\n",
      "yets\n",
      "has tym\" pr\n",
      "에포크 3\n",
      "1565/1565 [==============================] - 121s 77ms/step - loss: 1.5232\n",
      "--- 시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
      "through fo\"\n",
      "------ 온도: 0.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through formerly and as a contemptive the interrised and also the propersian and a man and in the contempting of the propersome the propersionality of the propersian and interest the man with the strength of the still and also the stronger of the result of the state of the propersionality of the storied formed and all the result of the strong the strong and also in the propersome the interrouse of the prope\n",
      "------ 온도: 0.5\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through form as it is a so to endure as the example of the state is the like to the soul of the propersionality, at the protect of the also the condection of the so or the fact in the soul and mankind is such as a god and all the promined in the labour of a sureless and all the false\n",
      "of the many at the will to which the spirit of the masters and the result and all the astimate and as it were a prooring and \n",
      "------ 온도: 1.0\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through formerlative, nothing at anyshours of the resientems above ageness of closes, in them of cail the refunce encendy the stroging and muld propresusotion us, as a sa circemstally. the\n",
      "religions in the finally -the means,\n",
      "it this tage of celtured resists, he of ranger frommet o also\n",
      "man be\n",
      "prooursious imis\n",
      "from the ackuatisy, this constantly beline of rranted, are religion and\n",
      "they also one many\n",
      "into th\n",
      "------ 온도: 1.2\n",
      "the slowly ascending ranks and classes, in which,\n",
      "through for lacting men of time in\n",
      "mopy, he is\n",
      "nothing, is de caussays\n",
      "aiticulals respance, hompen.. itver owing\n",
      "ourselvenisats\" ie that ifforical oledance? they they dove weanyseod form). the positiclish\n",
      "to the oachs\n",
      "himself,inate\n",
      " so much, brenow-\"edilianness me friedsm propty it in e first\n",
      "lineved conticuol,yf drubses as\n",
      "alfur in per ad--leard mi!s\n",
      "hinh noisagnedd, of this\n",
      "vaugle,-not\n",
      "simpoctic simpysing\n",
      "에포크 4\n",
      " 634/1565 [===========>..................] - ETA: 1:14 - loss: 1.4773"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m60\u001b[39m):     \u001b[38;5;66;03m# 60에포크동안 훈련\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m에포크\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     seed_text \u001b[38;5;241m=\u001b[39m text[start_index: start_index \u001b[38;5;241m+\u001b[39m  maxlen]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- 시드 텍스트: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m seed_text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 텍스트 생성 루프\n",
    "\n",
    "import random\n",
    "import sys\n",
    "\n",
    "random.seed(42)\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "for epoch in range(1, 60):     # 60에포크동안 훈련\n",
    "    print('에포크', epoch)\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "    \n",
    "    seed_text = text[start_index: start_index +  maxlen]\n",
    "    print('--- 시드 텍스트: \"' + seed_text + '\"')\n",
    "    \n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ 온도:', temperature)\n",
    "        generated_text = seed_text\n",
    "        sys.stdout.write(generated_text)\n",
    "        \n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.          # 지금까지 생성된 글자를 원핫인코딩으로 바꿈\n",
    "            \n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c411a5b",
   "metadata": {},
   "source": [
    "시드 텍스트 'the slowly ascending ranks and classes, inwhice, through fo'을 무작위로 시드텍스트로 선택한 뒤 temperature에 따라 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1813c68",
   "metadata": {},
   "source": [
    "# 8.2~3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af361bd0",
   "metadata": {},
   "source": [
    "그 이외에 이미지를 비슷하게 예술적으로 변경하는 딥드림, 뉴럴스타일 트랜스퍼 등등 존재. 코드는 쓰고싶으면 알아서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e155d",
   "metadata": {},
   "source": [
    "# 8.4 변이형 오토인코더를 사용한 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44221722",
   "metadata": {},
   "source": [
    "- 변이형 오토인코더(VAE) : 이미지의 잠재 공간에서 샘플링해서 완전히 새로운 이미지나 기존 이미지를 변형하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24c08a",
   "metadata": {},
   "source": [
    "## 8.4.1 이미지의 잠재 공간에서 샘플링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ab1d3",
   "metadata": {},
   "source": [
    "잠재공간의 한 포인트를 입력으로 받아 이미지를 출력하는 모듈은 생성자(GAN에서) or 디코더(VAE)라고 부름\n",
    "\n",
    "잠재공간이 만들어지면 여기서 포인트 하나를 특정/무작위 샘플링을 통해 이미지 생성 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd912e",
   "metadata": {},
   "source": [
    "## VAE의 작동방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdfadd",
   "metadata": {},
   "source": [
    "1. 인코더 모듈이 입력 샘플 input_img를 잠재 공간의 두 파라미터 z_mean과 z_log_var로 변환\n",
    "2. 입력 이미지가 생성되었다고 가정한 잠재공간의 정규분포에서 포인트 z를 z = z_mean + exp(0.5 * z_log_var) * epsilon 처럼 무작위로 샘플링\n",
    "3. 디코더 모듈은 잠재 공간의 이 포인트를 원본 입력 이미지르 매핑하여 복원\n",
    "\n",
    "VAE는 2개의 손실함수 존재\n",
    "- 재구성 손실 : 디코딩된 샘플이 원본 입력과 동일하도록 만듬\n",
    "- 규제 손실 : 잠재 공간을 잘 형성하고 훈련 데이터에 과대적합을 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6e22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE 인코더 네트워크\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "img_shape = (28, 28, 1)\n",
    "batch_size=16\n",
    "latent_dim=2\n",
    "\n",
    "input_img = keras.Input(shape=img_shape)\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79be6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠재공간 샘플링함수\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape = (K.shape(z_mean)[0], latent_dim), mean=0, stddev=1)\n",
    "    \n",
    "    return z_mean, K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf66665",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# VAE 디코더 네트워크\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(np\u001b[38;5;241m.\u001b[39mprod(shape_before_flattening[\u001b[38;5;241m1\u001b[39m:]), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(decoder_input)\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mReshape(shape_before_flattening[\u001b[38;5;241m1\u001b[39m:])(x)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend.py:1470\u001b[0m, in \u001b[0;36mint_shape\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1470\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m   1471\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1472\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(shape\u001b[38;5;241m.\u001b[39mas_list())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# VAE 디코더 네트워크\n",
    "\n",
    "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "x = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "\n",
    "decoder = Model(decoder_input, x)\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcad643",
   "metadata": {},
   "source": [
    "# 8.5 적대적 생성 신경망(GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d4394",
   "metadata": {},
   "source": [
    "GAN은 위조 이미지를 생성하는 생성자와 그를 바탕으로 진위여부를 판별하는 판별자로 구분. 판별자가 진짜라고 판정할 때까지 반복해서 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef57bf7",
   "metadata": {},
   "source": [
    "## 8.5.3 생성자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e7b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32768)             1081344   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32768)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_286 (Conv2D)         (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_287 (Conv2D)         (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_288 (Conv2D)         (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_289 (Conv2D)         (None, 32, 32, 3)         37635     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim=32\n",
    "height=32\n",
    "width=32\n",
    "channels=3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a967c80",
   "metadata": {},
   "source": [
    "## 8.5.4 판별자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b563da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_290 (Conv2D)         (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_291 (Conv2D)         (None, 14, 14, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_292 (Conv2D)         (None, 6, 6, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_293 (Conv2D)         (None, 2, 2, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da20fee",
   "metadata": {},
   "source": [
    "## 8.5.5 적대적 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a37db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6b20f",
   "metadata": {},
   "source": [
    "## 8.5.6 DCGAN 훈련방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bbc3b",
   "metadata": {},
   "source": [
    "1. 잠재공간에서 무작위로 포인트를 뽑음(랜덤 노이즈)\n",
    "2. 이 랜덤 노이즈를 사용하여 generator에서 이미지를 생성\n",
    "3. 생성된 이미지와 진짜 이미지를 섞음\n",
    "4. 진짜와 가짜가 섞인 이미지와 이에 대응하는 타기을 사용하여 discriminator를 훈련\n",
    "5. 잠재 공간에서 무작위로 새로운 포인트를 뽑음\n",
    "6. 이 랜덤 벡터를 사용하여 gan을 훈련. 모든 타깃은 '진짜'로 설정. 즉 생성자는 판별자를 속이도록 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609aaa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "판별자 손실: 1.6427397\n",
      "적대적 손실: 0.0006525054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m random_latent_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39m(batch_size, latent_dim))\n\u001b[0;32m     33\u001b[0m misleading_targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, \u001b[38;5;241m1\u001b[39m))     \u001b[38;5;66;03m# 모두 진짜 이미지라고 레이블 생성\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m a_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_latent_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmisleading_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m start \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m-\u001b[39m batch_size:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:1075\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_sample_weight_modes(sample_weights\u001b[38;5;241m=\u001b[39msample_weights)\n\u001b[0;32m   1074\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_train_function()\n\u001b[1;32m-> 1075\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_metrics:\n\u001b[0;32m   1078\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend.py:4284\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4279\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4280\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4281\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[0;32m   4282\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4284\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4285\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[0;32m   4287\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4289\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4290\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1484\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.utils import array_to_img\n",
    "\n",
    "(X_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train[y_train.flatten() == 6]         # 클래스가 6인 데이터만 선택\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0],) + (height, width, channels)).astype('float32') / 255.     # 데이터 정규화\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'C:/Users/ytnal/python/케라스창시자/datasets/gan_images/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "start = 0\n",
    "\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))   # 잠재공간에서 무작위로 샘플링\n",
    "    \n",
    "    generated_images = generator.predict(random_latent_vectors)    # 가짜 이미지를 디코딩\n",
    "    \n",
    "    stop = start + batch_size\n",
    "    real_images = X_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])  # 진짜와 가짜를 구분하여 레이블을 합침\n",
    "    labels += 0.05 * np.random.random(labels.shape)   # 레이블에 랜덤 노이즈를 추가\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)   # 판별자 훈련\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))     # 모두 진짜 이미지라고 레이블 생성\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    \n",
    "    if start > len(X_train) - batch_size:\n",
    "        start = 0\n",
    "    if step % 100 == 0:     # 100스텝마다 중간중간 저장\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print('판별자 손실:', d_loss)\n",
    "        print('적대적 손실:', a_loss)\n",
    "        \n",
    "        img = array_to_img(generated_images[0] * 255, scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
    "        \n",
    "        img = array_to_img(real_images[0] * 255, scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a85a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
